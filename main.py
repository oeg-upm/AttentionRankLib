

from src.attentionrank.attentions import ModelEmbedding
from src.attentionrank.preprocessing import preprocessing_module




bertemb= ModelEmbedding('bert-base-uncased')
#bertemb(["feature dollar",'Wolverstein'])

preprocessing_module(root_folder)

#step_5(root_folder,dataset_name)




'''
#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
#model = TFBertModel.from_pretrained("bert-base-uncased")

root_folder = './SemEval2017/'
dataset_name = 'SemEval2017'
preprocessing_module(root_folder)

#step_5(root_folder)def step_5(root_folder,dataset_name):
#step6()
#step7()
#step8()
#step9()
#step10()
#step11()



'''






